{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('general_env': conda)",
   "display_name": "Python 3.8.5 64-bit ('general_env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ff45090782e9a020abf2b81d834d67e955346823624e3a8901eedb85a5229128"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "    \"\"\"\n",
    "    ---------------------------------------------------\n",
    "    ----- TÓPICO: Machine Learning - Transformers -----\n",
    "    ---------------------------------------------------\n",
    "    Arquivo de testes para validar as implementações\n",
    "    presentes no módulo ml do pacote bebop\n",
    "\n",
    "    Sumário\n",
    "    -----------------------------------\n",
    "    1. Pipelines\n",
    "    -----------------------------------\n",
    "    \"\"\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Machine Learning - Transformers\n",
    "\n",
    "O objetivo desse notebook é propor implementações utilizando os componentes de Machine Learning desenvolvidos no módulo `transformers.py`. Em geral, as classes desenvolvidas visam facilitar a construção de _Pipelines_ de pré processamento de dados em projetos atrelados a construção de modelos, sendo responsáveis por proporcionar as principais operações em fluxos do tipo. Entre as classes implementadas, é possível listar:\n",
    "    \n",
    "\n",
    "    ColsFormatting()\n",
    "    FeatureSelection()\n",
    "    TargetDefinition()\n",
    "    DropDuplicates()\n",
    "    SplitData()\n",
    "    DummiesEncoding()\n",
    "    FillNullData()\n",
    "    DropNullData()\n",
    "    TopFeaturesSelector()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "- _Preparação Inicial_\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import pandas as pd \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: bebop==0.0.1 from file:///home/paninit/workspaces/python-components/dist/bebop-0.0.1-py3-none-any.whl in /home/paninit/anaconda3/envs/general_env/lib/python3.8/site-packages (0.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ../../dist/bebop-0.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1309, 12)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Lendo base de dados\n",
    "raw_data = pd.read_csv('../titanic_data/titanic.csv')\n",
    "print(raw_data.shape)\n",
    "raw_data.head()"
   ]
  },
  {
   "source": [
    "___\n",
    "* _ColsFormatting()_ \n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A aplicação do método `fit_transform()` da classe `ColsFormatting()` permite uma transformação básica na nomenclatura das colunas do DataFrame. Com isso, é possível proporcionar uma padronização no desenvolvimento de projetos a partir do alinhamento do código para as referências colunas geradas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Colunas do arquivo raw: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\nColunas após formatação: ['passengerid', 'survived', 'pclass', 'name', 'sex', 'age', 'sibsp', 'parch', 'ticket', 'fare', 'cabin', 'embarked']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   passengerid  survived  pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                name     sex   age  sibsp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   parch            ticket     fare cabin embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>passengerid</th>\n      <th>survived</th>\n      <th>pclass</th>\n      <th>name</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>ticket</th>\n      <th>fare</th>\n      <th>cabin</th>\n      <th>embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Importando classe\n",
    "from ml.transformers import ColsFormatting\n",
    "\n",
    "# Instanciando objeto\n",
    "formatter = ColsFormatting()\n",
    "\n",
    "# Transformando DataFrame\n",
    "print(f'Colunas do arquivo raw: {list(raw_data.columns)}')\n",
    "df_cols_form = formatter.fit_transform(raw_data)\n",
    "\n",
    "# Verificando resultado\n",
    "print(f'Colunas após formatação: {list(df_cols_form.columns)}')\n",
    "df_cols_form.head()"
   ]
  },
  {
   "source": [
    "_Aplicação:_\n",
    "\n",
    "Na prática, a classe `ColsFormatting()` pode ser utilizada em pipelines de pré processamento ou de pós leitura dos dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "* _FeatureSelection()_\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Ao aplicar o método `fit_transform()` da classe `FeatureSelection()`, é possível aplicar o processo de seleção de features em uma base de dados lida. Com isso, é possível automatizar o processo de filtragem de colunas de bases brutas, eliminando colunas chaves e mantendo apenas features relevantes para um possível model de Machine Learning a ser desenvolvido ou aplicado."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Features após a seleção: ['survived', 'name', 'sex', 'age']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   survived                                               name     sex   age\n",
       "0       0.0                            Braund, Mr. Owen Harris    male  22.0\n",
       "1       1.0  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0\n",
       "2       1.0                             Heikkinen, Miss. Laina  female  26.0\n",
       "3       1.0       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0\n",
       "4       0.0                           Allen, Mr. William Henry    male  35.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>survived</th>\n      <th>name</th>\n      <th>sex</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Importando classe\n",
    "from ml.transformers import FeatureSelection\n",
    "\n",
    "# Instanciando objeto\n",
    "features = ['survived', 'name', 'sex', 'age']\n",
    "selector = FeatureSelection(features=features)\n",
    "\n",
    "# Transformando base\n",
    "df_selected = selector.fit_transform(raw_data)\n",
    "\n",
    "# Visualizando resultado\n",
    "print(f'Features após a seleção: {list(df_selected.columns)}')\n",
    "df_selected.head()"
   ]
  },
  {
   "source": [
    "_Aplicação:_ \n",
    "\n",
    "Na prática, o transformador `FeatureSelection()` pode ser usado em pipelines iniciais de pré processamento ou de póś leitura dos dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "* _TargetDefinition()_\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Ao aplicar o método `fit_transform()` da classe `TargetDefinition()`, é possível aplicar um processo de transformação nas entradas de uma coluna `target`, modificando entradas categóricas para entradas numéricas de acordo com a informação da classe positiva do modelo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Primeiros elementos da classe target original (survived): [0. 1. 1. 1. 0.]\nPrimeiros elementos da classe target resutante (target): [0 1 1 1 0]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   passengerid  pclass                                               name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      sex   age  sibsp  parch            ticket     fare cabin embarked  \\\n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S   \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C   \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S   \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>passengerid</th>\n      <th>pclass</th>\n      <th>name</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>ticket</th>\n      <th>fare</th>\n      <th>cabin</th>\n      <th>embarked</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Importando classe\n",
    "from ml.transformers import TargetDefinition\n",
    "\n",
    "# Instanciando objeto\n",
    "target_def = TargetDefinition(target_col='survived', pos_class=1.0)\n",
    "\n",
    "# Transformando DataFrame\n",
    "df_target_def = target_def.fit_transform(raw_data)\n",
    "\n",
    "# Visualizando resultado\n",
    "print(f'Primeiros elementos da classe target original (survived): {raw_data.head()[\"survived\"].values}')\n",
    "print(f'Primeiros elementos da classe target resutante (target): {df_target_def.head()[\"target\"].values}')\n",
    "df_target_def.head()"
   ]
  },
  {
   "source": [
    "_Aplicação:_ \n",
    "\n",
    "Na prática, o transformador `TargetDefinition()` pode ser usado em pipelines iniciais de pré processamento ou de póś leitura dos dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "* _DropDuplicates()_\n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "O método `fit_transform()` da classe `DropDuplicates()` remove das duplicatas de uma base de dados fornecida."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Volumetria antes da remoção de duplicatas: 1309\nVolumetria após a remoção das duplicatas: 1309\nQuantidade de dados duplicatos na base original: 0\n"
     ]
    }
   ],
   "source": [
    "# Importando classe\n",
    "from ml.transformers import DropDuplicates\n",
    "\n",
    "# Instanciando objeto\n",
    "dup_dropper = DropDuplicates()\n",
    "\n",
    "# Executando função\n",
    "df_nodup = dup_dropper.fit_transform(raw_data)\n",
    "print(f'Volumetria antes da remoção de duplicatas: {len(raw_data)}')\n",
    "print(f'Volumetria após a remoção das duplicatas: {len(df_nodup)}')\n",
    "print(f'Quantidade de dados duplicatos na base original: {raw_data.duplicated().sum()}')"
   ]
  },
  {
   "source": [
    "_Aplicação:_ \n",
    "\n",
    "Na prática, o transformador `DropDuplicates()` pode ser usado em pipelines iniciais de pré processamento ou de póś leitura dos dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "* _SplitData()_ \n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Ao executar o método `fit_transform()` da classe `SplitData()`, é feita a separação de uma base de dados em dados de treino e teste. Na prática, esse transformador pode ser utilizado como um último passo dentro de um pipeline de pré processamento ou de pós leitura, sendo este o responsável por gerar as bases X_train, X_test, y_train e y_test para a modelagem subsequente."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Volumetria de X_train: (1047, 12)\nVolumetria de X_test: (262, 12)\nVolumetria de y_train: (1047,)\nVolumetria de y_test: (262,)\n"
     ]
    }
   ],
   "source": [
    "# Importando classe\n",
    "from ml.transformers import SplitData\n",
    "\n",
    "# Instanciando objeto\n",
    "splitter = SplitData(target='survived', test_size=.20, random_state=42)\n",
    "\n",
    "# Transformando dados\n",
    "X_train, X_test, y_train, y_test = splitter.fit_transform(raw_data)\n",
    "print(f'Volumetria de X_train: {X_train.shape}')\n",
    "print(f'Volumetria de X_test: {X_test.shape}')\n",
    "print(f'Volumetria de y_train: {y_train.shape}')\n",
    "print(f'Volumetria de y_test: {y_test.shape}')"
   ]
  },
  {
   "source": [
    "_Aplicação:_ \n",
    "\n",
    "Como mencionado acima, a classe `SplitData()` pode ser utilizada como um último em um fluxo de pós leitura da base origem. Considerando que este pipeline de pós leitura irá contemplar transformadores cujo contexto de aplicação está relacionado a base como um todo (sem a separação em treino e teste), `SplitData()` atua como uma finalização do pipe, sendo o primeiro passo para a construção de pipelines subsequentes de data prep."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "* _DummiesEncoding()_ \n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A classe `DummiesEncoding()`, a partir do seu método herdado `fit_transform()`, permite com que seja aplicado o processo de encoding em variáveis categóricas de uma base de dados lida. Seu funcionamento é baseado na aplicação do método `get_dummies()` do pandas e seu contexto de utilização está relacionado a pipelines categóricos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Features categóricas consideradas: ['sex', 'embarked']\nFeatures após o encoding: ['sex_female', 'sex_male', 'sex_nan', 'embarked_C', 'embarked_Q', 'embarked_S', 'embarked_nan']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   sex_female  sex_male  sex_nan  embarked_C  embarked_Q  embarked_S  \\\n",
       "0           0         1        0           0           0           1   \n",
       "1           1         0        0           1           0           0   \n",
       "2           1         0        0           0           0           1   \n",
       "3           1         0        0           0           0           1   \n",
       "4           0         1        0           0           0           1   \n",
       "\n",
       "   embarked_nan  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex_female</th>\n      <th>sex_male</th>\n      <th>sex_nan</th>\n      <th>embarked_C</th>\n      <th>embarked_Q</th>\n      <th>embarked_S</th>\n      <th>embarked_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Importando classe\n",
    "from ml.transformers import DummiesEncoding\n",
    "\n",
    "# Separando dados categóricos\n",
    "cat_attribs = [col for col, dtype in raw_data.dtypes.items() if (dtype == 'object') and (col not in ['name', 'ticket', 'cabin'])]\n",
    "df_cat = raw_data[cat_attribs]\n",
    "\n",
    "# Instanciando classe\n",
    "encoder = DummiesEncoding(dummy_na=True)\n",
    "df_encoded = encoder.fit_transform(df_cat)\n",
    "\n",
    "# Retornando features após o encoding e visualizando o resultado\n",
    "encoded_features = encoder.features_after_encoding\n",
    "print(f'Features categóricas consideradas: {cat_attribs}')\n",
    "print(f'Features após o encoding: {encoded_features}')\n",
    "df_encoded.head()"
   ]
  },
  {
   "source": [
    "_Aplicação:_\n",
    "\n",
    "Assim como mencionado acima, o transformador `DummiesEncoding()` pode ser aplicado em um pipeline de preparação de dados categóricos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "* _FillNullData()_ \n",
    "___ "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Ao executar o método `fit_transform()` da classe `FillNullData()`, os dados nulos do conjunto de variáveis definidas nos atributos da classe são preenchidos com um indicador numérico também definido por um dos atributos da classe."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dados nulos:\npassengerid      0\npclass           0\nage            263\nsibsp            0\nparch            0\nfare             1\ntarget           0\ndtype: int64\n\nDados nulos após a transformação:\npassengerid    0\npclass         0\nage            0\nsibsp          0\nparch          0\nfare           0\ntarget         0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importando classe\n",
    "from ml.transformers import FillNullData\n",
    "\n",
    "# Filtrando dados numéricos\n",
    "num_attribs = [col for col, dtype in raw_data.dtypes.items() if (dtype != 'object') and (col != 'survived')]\n",
    "df_num = raw_data[num_attribs]\n",
    "print(f'Dados nulos:\\n{df_num.isnull().sum()}')\n",
    "\n",
    "# Aplicando preenchimento dos nulos\n",
    "null_filler = FillNullData(cols_to_fill=['age', 'fare'], value_fill=0)\n",
    "df_filled = null_filler.fit_transform(df_num)\n",
    "print(f'\\nDados nulos após a transformação:\\n{df_filled.isnull().sum()}')"
   ]
  },
  {
   "source": [
    "_Aplicação:_ \n",
    "\n",
    "A classe `FillNullData()` pode ser utilizada como um dos blocos fundamentais em um pipeline numérico de preparação dos dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "___\n",
    "* _DropNullData()_ \n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A classe `DropNullData()` abre a possibilidade de eliminação dos dados nulos de uma base de dados fornecida"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dados nulos:\npassengerid      0\npclass           0\nage            263\nsibsp            0\nparch            0\nfare             1\ntarget           0\ndtype: int64\n\nDados nulos após a transformação:\npassengerid      0\npclass           0\nage            264\nsibsp            0\nparch            0\nfare           264\ntarget           0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importando classe\n",
    "from ml.transformers import DropNullData\n",
    "\n",
    "# Filtrando dados numéricos\n",
    "num_attribs = [col for col, dtype in raw_data.dtypes.items() if (dtype != 'object') and (col != 'survived')]\n",
    "df_num = raw_data[num_attribs]\n",
    "print(f'Dados nulos:\\n{df_num.isnull().sum()}')\n",
    "\n",
    "# Aplicando drop dos nulos\n",
    "null_dropper = DropNullData(cols_dropna=['age', 'fare'])\n",
    "df_drop = null_dropper.fit_transform(df_num)\n",
    "print(f'\\nDados nulos após a transformação:\\n{df_drop.isnull().sum()}')"
   ]
  },
  {
   "source": [
    "___\n",
    "* _TopFeatureSelector()_ \n",
    "___"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A classe `TopFeaureSelector()` permite, a partir da execução de seu método `fit_transform()`, a seleção dinâmica de features de uma base a partir de um set de `feature importances` previamente passado como input. A ideia dessa classe é aplicar uma filtragem das features mais importantes de uma base, dado o resultado prévio de um modelo de Machine Learning já treinado. Dessa forma, é possível adicionar esse transformador a um pipeline final de prep e modelagem, aplicando a seleção de features como um último passo desse fluxo de modo a utilizar apenas as variáveis mais importantes consideradas por um modelo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "kth(=-3) out of bounds (2)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-edbdf363da56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Instanciando classe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtop_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTopFeatureSelector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_importances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdf_top_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/general_env/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/general_env/lib/python3.8/site-packages/ml/transformers.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/general_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \"\"\"\n\u001b[0;32m--> 832\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argpartition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/general_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: kth(=-3) out of bounds (2)"
     ]
    }
   ],
   "source": [
    "# Importando classe\n",
    "from ml.transformers import TopFeatureSelector\n",
    "import numpy as np\n",
    "\n",
    "# Criando feature importances fake\n",
    "features = list(raw_data.drop('survived', axis=1).columns)\n",
    "importances = [np.random.randint(1, 10) for i in range(len(features))]\n",
    "feature_importances = pd.DataFrame(zip(features, importances))\n",
    "\n",
    "# Instanciando classe\n",
    "top_selector = TopFeatureSelector(feature_importance=feature_importances, k=5)\n",
    "df_top_features = top_selector.fit_transform(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  7, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "indices = np.sort(np.argpartition(np.array(feature_importances[0]), -5)[-5:])\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), array([ 1,  3,  5,  7, 11]))' is an invalid key",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-a2eb1e5776a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/general_env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/general_env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2893\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), array([ 1,  3,  5,  7, 11]))' is an invalid key"
     ]
    }
   ],
   "source": [
    "raw_data[:, indices]"
   ]
  },
  {
   "source": [
    "## Pipeline de Pós Leitura"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Nessa sessão, será construído um Pipeline de pós leitura dos dados utilizado para aplicar transformações iniciais em uma base dados recém importada."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Visualizando X_train\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     passengerid  pclass     sex   age  sibsp  parch    fare embarked\n",
       "772          773       2  female  57.0      0      0  10.500        S\n",
       "543          544       2    male  32.0      1      0  26.000        S\n",
       "289          290       3  female  22.0      0      0   7.750        Q\n",
       "10            11       3  female   4.0      1      1  16.700        S\n",
       "147          148       3  female   9.0      2      2  34.375        S"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>passengerid</th>\n      <th>pclass</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>772</th>\n      <td>773</td>\n      <td>2</td>\n      <td>female</td>\n      <td>57.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>10.500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>543</th>\n      <td>544</td>\n      <td>2</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>26.000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>289</th>\n      <td>290</td>\n      <td>3</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.750</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>3</td>\n      <td>female</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>16.700</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>148</td>\n      <td>3</td>\n      <td>female</td>\n      <td>9.0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>34.375</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# Importando bibliotecas\n",
    "from sklearn.pipeline import Pipeline\n",
    "from ml.transformers import ColsFormatting, FeatureSelection, TargetDefinition, DropDuplicates, SplitData\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Lendo dados\n",
    "df = pd.read_csv('../titanic_data/titanic.csv')\n",
    "features = ['passengerid', 'survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
    "\n",
    "# Construindo pipeline de pós leitura\n",
    "initial_pipeline = Pipeline([\n",
    "    ('formatter', ColsFormatting()),\n",
    "    ('selector', FeatureSelection(features=features)),\n",
    "    ('target_generator', TargetDefinition(target_col='survived', pos_class=1.0)),\n",
    "    ('dup_dropper', DropDuplicates()),\n",
    "    ('splitter', SplitData(target='target'))\n",
    "])\n",
    "\n",
    "# Executando pipeline\n",
    "X_train, X_test, y_train, y_test = initial_pipeline.fit_transform(raw_data)\n",
    "print('Visualizando X_train')\n",
    "X_train.head()"
   ]
  },
  {
   "source": [
    "## Pipelines de DataPrep"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Após a implementação de um pipeline initial de transformação, é possível construir pipelines específicos para dados numéricos e categóricos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando dados numéricos e categóricos\n",
    "num_attribs = [col for col, dtype in X_train.dtypes.items() if dtype != 'object']\n",
    "cat_attribs = [col for col, dtype in X_train.dtypes.items() if dtype == 'object']\n",
    "\n",
    "# Construindo pipeline numérico\n",
    "num_pipeline = Pipeline([\n",
    "    ('null_filler', FillNullData(value_fill=0)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Construindo pipeline categórico\n",
    "cat_pipeline = Pipeline([\n",
    "    ('encoder', DummiesEncoding())\n",
    "])\n",
    "\n",
    "# Unindo pipelines\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', cat_pipeline, cat_attribs)\n",
    "])\n",
    "\n",
    "# Aplicando pipeline pros dados de treino e teste\n",
    "X_train_prep = full_pipeline.fit_transform(X_train)\n",
    "X_test_prep = full_pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}